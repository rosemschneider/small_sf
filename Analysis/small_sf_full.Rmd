---
title: "Small_SF"
author: "Rose M. Schneider"
date: "4/3/2019"
output: html_document
---
```{r, include = FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/small_sf/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(memisc)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

---

##Data management
###Load
```{r}
#load study 1 data
data.raw.study1 <- read.csv("~/Documents/Projects/small_sf/Data/small_sf_study1.csv")
data.raw.study2 <- read.csv("~/Documents/Projects/small_sf/Data/small_sf_study2.csv")

##Exclude any pilots and copypaste
data.raw.study1 %<>%
  filter(SID != "CopyPasteMe", 
         Exclusion_reason != "Pilot")%>%
  droplevels()%>%
  # dplyr::select(-X, -X.1, -X.2, -X.3, -X.4)%>%
  mutate(Age = as.numeric(as.character(Age)))

data.raw.study2 %<>%
  filter(SID != "CopyPasteMe", 
         Exclusion_reason != "Pilot")%>%
  droplevels()%>%
  # dplyr::select(-X, -X.1, -X.2, -X.3, -X.4)%>%
  mutate(Age = as.numeric(as.character(Age)))
```

###Exclusions - all
```{r}
#how many kids pre-exclusions?
#exp.1
data.raw.study1 %>%
  distinct(SID, Age)%>%
  summarise(n = n())

#exp.2
data.raw.study2 %>%
  distinct(SID, Age)%>%
  summarise(n = n())

#Why are kids excluded?
#exp.1
data.raw.study1 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude, Exclusion_reason)%>%
  group_by(Exclusion_reason)%>%
  summarise(n = n())
#exp.2
data.raw.study2 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude, Exclusion_reason)%>%
  group_by(Exclusion_reason)%>%
  summarise(n = n())

##Exclude
#exp.1
data.raw.study1 %<>%
  filter(Exclude != 1)%>%
  droplevels()
#exp.2
data.raw.study2 %<>%
  filter(Exclude != 1)%>%
  droplevels()
```

###Exclude trials
```{r}
#exp.1
data.raw.study1 %<>%
  mutate(Exclude_trial = ifelse(is.na(Exclude_trial), "0", as.character(Exclude_trial)))%>%
  filter(Exclude_trial != "1")

#exp.2
data.raw.study2 %<>%
  mutate(Exclude_trial = ifelse(is.na(Exclude_trial), "0", as.character(Exclude_trial)))%>%
  filter(Exclude_trial != "1")

#how many kids failed training for SF?
#exp.1
data.raw.study1 %>%
  filter(Task == "SF", 
         Trial_number == "Training", 
         Correct == "0")%>%
  summarise(n = n())

#exp.2
data.raw.study2 %>%
  filter(Task == "SF", 
         Trial_number == "Training", 
         Correct == "0")%>%
  summarise(n = n())

##exclude training for SF
#exp.1
data.raw.study1 %<>%
  mutate(Trial_number = ifelse(is.na(Trial_number), "HC", as.character(Trial_number)))%>%
  filter(Trial_number != "Training")

##exclude training for SF
#exp.2
data.raw.study2 %<>%
  mutate(Trial_number = ifelse(is.na(Trial_number), "HC", as.character(Trial_number)))%>%
  filter(Trial_number != "Training")
```

###Rename
```{r}
all.data.study1 <- data.raw.study1

all.data.study2 <- data.raw.study2
```
---

#Checking knower level classifications
```{r}
#study 1
given.ms <- all.data.study1 %>%
  mutate(Knower_level = ifelse(Knower_level == "CP", 6, as.numeric(as.character(Knower_level)))) %>% #for function below
  filter(Task == "Give_N", 
         !is.na(Task_item))%>%
  group_by(SID, Knower_level, Task_item)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))

#overall check - an N-knower should have gotten at least .67 mean performance for a given N
check <- given.ms %>%
  filter(Task_item == Knower_level)%>%
  filter(mean < .66)

if(length(check$SID) > 0) {
  print("CHECK STUDY 1 KLs")
}

#study 2
given.ms <- all.data.study2 %>%
  mutate(Knower_level = ifelse(Knower_level == "CP", 6, as.numeric(as.character(Knower_level)))) %>% #for function below
  filter(Task == "Give_N", 
         !is.na(Task_item))%>%
  group_by(SID, Knower_level, Task_item)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))

#overall check - an N-knower should have gotten at least .67 mean performance for a given N
check <- given.ms %>%
  filter(Task_item == Knower_level)%>%
  filter(mean < .66)

if(length(check$SID) > 0) {
  print("CHECK STUDY 2 KLs")
}
```

###Change correct to numeric
```{r}
all.data.study1 %<>%
  mutate(Correct = as.numeric(as.character(Correct)))

all.data.study2 %<>%
  mutate(Correct = as.numeric(as.character(Correct)))
```

---

##Demographics
By N-level
```{r}
#by N level
#study1
all.data.study1 %>%
  group_by(Knower_level)%>%
  distinct(SID, Age, Knower_level)%>%
  summarise(n = n(), 
            mean_age = mean(Age, na.rm = TRUE), 
            sd_age = sd(Age, na.rm = TRUE)) %>%
  kable()

#study2
all.data.study2 %>%
  group_by(Knower_level)%>%
  distinct(SID, Age, Knower_level)%>%
  summarise(n = n(), 
            mean_age = mean(Age, na.rm = TRUE), 
            sd_age = sd(Age, na.rm = TRUE)) %>%
  kable()

#boxplot
#study1
all.data.study1 %>%
  ggplot(aes(x = Knower_level, y = Age, fill = Knower_level)) + 
  geom_boxplot() + 
  theme_bw() + 
  labs(title = 'Study 1: Age by knower level')

#study2
all.data.study2 %>%
  ggplot(aes(x = Knower_level, y = Age, fill = Knower_level)) + 
  geom_boxplot() + 
  theme_bw() +
  labs(title = 'Study 2: Age by knower level')

#by CP_subset
#Study 1 
all.data.study1 %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", 
                            "Subset"))
#Study 2 
all.data.study2 %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", 
                            "Subset"))

#study 1
all.data.study1 %>%
  ggplot(aes(x = CP_subset, y = Age, fill = CP_subset)) + 
  geom_boxplot() + 
  theme_bw() + 
  scale_fill_brewer(palette = "Set1") +
  labs(title = 'Study 1: Age by CP/Subset')

#study 2
all.data.study2 %>%
  ggplot(aes(x = CP_subset, y = Age, fill = CP_subset)) + 
  geom_boxplot() + 
  theme_bw() + 
  scale_fill_brewer(palette = "Set1") +
  labs(title = 'Study 2: Age by CP/Subset')

```



---

#Unit Task Visualizations 

##Study 1: Mean performance for all participants
By N-level
```{r}
##descriptives
all.data.study1 %>%
  filter(Task == "SF", 
         Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  group_by(Knower_level, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            sd= sd(Correct, na.rm = TRUE))%>%
  kable()

#visualization
all.data.study1 %>%
  filter(Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  filter(Task == "SF")%>%
  group_by(Task_item, Knower_level)%>%
  summarise(mean = mean(Correct, na.rm = TRUE),
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Knower_level, group= Knower_level)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~Knower_level, ncol = 3) + 
  labs(x = "Number queried", y = "Mean Unit performance")
```

##Study 2: Mean performance for all participants

```{r}
##descriptives
all.data.study2 %>%
  filter(Task == "SF", 
         Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  group_by(Knower_level, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            sd= sd(Correct, na.rm = TRUE))%>%
  kable()

#visualization
all.data.study2 %>%
  filter(Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  filter(Task == "SF")%>%
  group_by(Task_item, Knower_level)%>%
  summarise(mean = mean(Correct, na.rm = TRUE),
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Knower_level, group= Knower_level)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~Knower_level, ncol = 3) + 
  labs(x = "Number queried", y = "Mean Unit performance")
```

##Study 1: Mean performance by CP/Subset

```{r}
all.data.study1 %>%
    filter(Task == "SF")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Task_item, CP_subset)%>%
   summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = CP_subset, group= CP_subset)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~CP_subset) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_brewer(palette = "Set1")+ 
  labs(x = "Number queried", y = "Mean Unit performance")
```

##Study 2: Mean performance by CP/Subset
```{r}
all.data.study2 %>%
    filter(Task == "SF")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Task_item, CP_subset)%>%
   summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = CP_subset, group= CP_subset)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~CP_subset) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_brewer(palette = "Set1")+ 
  labs(x = "Number queried", y = "Mean Unit performance")
```

---

#Highest Count
```{r}
##add highest count as a column
#study 1
hc.lookup <- all.data.study1 %>%
  filter(Task == "Highest_count")%>%
  dplyr::rename(highest_count = Response)%>%
  dplyr::select(SID, highest_count)

all.data.study1 <- right_join(all.data.study1, hc.lookup, by = "SID")

#HCs are being read in as factors - change to numeric
all.data.study1 %<>%
  mutate(highest_count = as.numeric(as.character(highest_count)))

#one kid didn't do highest count, so we will exclude them from analyses containing hc

#study 2
hc.lookup <- all.data.study2 %>%
  filter(Task == "Highest_count")%>%
  dplyr::rename(highest_count = Response)%>%
  dplyr::select(SID, highest_count)

all.data.study2 <- right_join(all.data.study2, hc.lookup, by = "SID")

#HCs are being read in as factors - change to numeric
all.data.study2 %<>%
  mutate(highest_count = as.numeric(as.character(highest_count)))

#one kid didn't do highest count, so we will exclude them from analyses containing hc
```

##Study 1: Histogram of HC
```{r}
all.data.study1 %>%
  filter(!is.na(highest_count))%>%
  distinct(SID, Age, CP_subset, highest_count)%>%
  ggplot(aes(x = highest_count, fill = CP_subset)) + 
   geom_histogram(color = "black")+
  theme_bw() + 
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Highest Count (unprompted)", y = "Count")
```

##Study 2: Histogram of HC
```{r}
all.data.study2 %>%
  filter(!is.na(highest_count))%>%
  distinct(SID, Age, CP_subset, highest_count)%>%
  ggplot(aes(x = highest_count, fill = CP_subset)) + 
   geom_histogram(color = "black")+
  theme_bw() + 
  scale_fill_brewer(palette = "Set1") + 
  labs(x = "Highest Count (unprompted)", y = "Count")
```

---

#Next Number: Study 2
Visualization of performance by KL
```{r}
##descriptives
all.data.study2 %>%
  filter(Task == "Next_number", 
         Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  group_by(Knower_level, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            sd= sd(Correct, na.rm = TRUE))%>%
  kable()

#visualization
all.data.study2 %>%
  filter(Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "CP")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  filter(Task == "Next_number")%>%
  group_by(Task_item, Knower_level)%>%
  summarise(mean = mean(Correct, na.rm = TRUE),
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Knower_level, group= Knower_level)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~Knower_level, ncol = 3) + 
  labs(x = "Number queried", y = "Mean Next Number performance")
```

##Study 2: Mean performance by CP/Subset
```{r}
all.data.study2 %>%
    filter(Task == "Next_number")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)))%>%
  group_by(Task_item, CP_subset)%>%
   summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = CP_subset, group= CP_subset)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~CP_subset) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_brewer(palette = "Set1")+ 
  labs(x = "Number queried", y = "Mean Next Number performance")
```

##Visualization of Unit vs. Next Number performance
```{r}
all.data.study2 %>%
  filter(Task == "SF" | 
           Task == "Next_number")%>%
  group_by(CP_subset, Task, Task_item)%>%
  summarise(n = n(), 
            mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = CP_subset, group= CP_subset)) +
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  facet_wrap(~Task) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_brewer(palette = "Set1")+ 
  labs(x = "Number queried", y = "Mean task performance")
```

---
#Analyses: Study 1
###Make SF model dfs 
```{r}
model.df.study1 <- all.data.study1 %>%
  filter(Task == "SF", 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)))
```

##Test 1: Do subset-knowers perform significantly better than chance on this task overall?
Yes: Significant Wald Z = 3.33, *p*= .0009
```{r}
#filter down to subset knowers
subset.chance.overall <- glmer(Correct ~ 1 + (1|SID), family = "binomial", 
                               data = subset(model.df.study1, CP_subset == "Subset"))
summary(subset.chance.overall)
```

##Test 2: Do subset-knowers perform significantly above chance for numbers WITHIN their knower level? 
Yes, subset-knowers perform significantly better than chance for numbers within their Knower Level; Wald Z = 5.19, *p* < .0001.
```{r}
##add to model.df whether a trial was within or outside knower level 
model.df.study1.within <- model.df.study1 %>%
  filter(CP_subset != "CP")%>%
  mutate(within_kl = ifelse(Task_item <= as.numeric(as.character(Knower_level)), "Within", "Outside"))

subset.chance.within.kl <- glmer(Correct ~ 1 + (1|SID), family = "binomial", 
                                 data = subset(model.df.study1.within, within_kl == "Within"))

summary(subset.chance.within.kl)
```

##Test 3: Do subset-knowers with greater levels of number exposure (HC) have more accurate performance overall
No, Chisq(1) = 0.66, *p* = .42
```{r}
##get highest count for each kid, add to model.df 
subset.hc <- glmer(Correct ~ highest_count + (1|SID), 
                   family = "binomial", data = subset(model.df.study1, CP_subset == "Subset"))

#compare to base
anova(subset.chance.overall, subset.hc, test = 'LRT')
```

##Test 4: Do subset-knowers with greater levels of number exposure have more accurate performance for numbers within their knower-level?
No; Chisq(1) = 0.65, *p* = .42
```{r}
subset.hc.within <- glmer(Correct ~ highest_count + (1|SID), 
                          family = "binomial", data = subset(model.df.study1.within, within_kl == "Within"))

#lrt to compare
anova(subset.chance.within.kl, subset.hc.within, test = 'LRT')
```


##Test 5: Do CP-knowers have significantly better performance on this task in comparison to subset-knowers?
CP-knowers are significantly more accurate on this task: Chisq(1) = 5.36, *p* = .02
```{r}
model.cp.study1 <- all.data.study1 %>%
  filter(Task == "SF", 
         !is.na(highest_count), 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)), 
          age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)))

#construct base model with age
cp.subset.base <- glmer(Correct ~ age.c + (1|SID), 
                        family = "binomial", data = model.cp.study1)

#add knower level - does this explain additional variance?
cp.subset.kl <- glmer(Correct ~ CP_subset + age.c + (1|SID), 
                      family = "binomial", data = model.cp.study1)

#compare - does KL improve the fit of the base model? 
anova(cp.subset.base, cp.subset.kl, test = 'LRT')
```

## Does counting exposure predict performance with both CP- and Subset-knowers?
Yes; Chisq(1) = 7.97, *p* = .005
```{r}
cp.hc <- glmer(Correct ~ highest_count + age.c + (1|SID), 
               family = "binomial", data = model.cp.study1)

#compare
anova(cp.subset.base, cp.hc, test = 'LRT')
```

##Finally, does KL explain anything on top of differences in HC?
No: When added to a model containing HC, KL does not explain additional variance
```{r}
##HC gets added first because it has a lower AIC
cp.hc.kl <- glmer(Correct ~ CP_subset +  highest_count + age.c + (1|SID), 
                  family = "binomial", data = model.cp.study1)

#compare
anova(cp.hc, cp.hc.kl, test = 'LRT')
```

##Correlation between age and unit task performance 
Marginally significant correlation between age and Unit task performance; *r* = .21, *p* = .08
```{r}
sf.ms <- all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Age)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

cor.test(sf.ms$mean, sf.ms$Age)
```

---

#Study 2

###Create data frame
```{r}
##This is for Next number AND SF analyses
model.df.study2 <- all.data.study2 %>%
  filter(Task == "SF" | 
           Task == "Next_number", 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)))
```

##Test 1: Comparison between Unit Task and Next Number performance for subset-knowers
Yes: Subset-knowers have significantly better performance on the Unit Task in comparison to the NN task: Wald Z = 6.42, *p* < .0001
```{r}
#make base
nn.v.sf.base <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset"))
#add task
nn.v.sf.task <- glmer(Correct ~ Task + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset"))
#compare
anova(nn.v.sf.base, nn.v.sf.task, test= 'LRT')#significant
summary(nn.v.sf.task)
```

##Test 2: Does Unit/NN performance differ for subset-knowers for items within count range?
Yes, even for items within a subset-knower's knower level, performance on SF is still significantly better than performance on NN: Wald Z = 4.58, *p* < .0001. 
```{r}
#add a term indicating whether item is within/outside knower level
model.df.study2.within <- model.df.study2 %>%
  mutate(within_kl = ifelse(Task_item <= as.numeric(as.character(Knower_level)), "Within", "Outside"), 
         within_kl = factor(within_kl))

#make base
within.nn.v.sf.base <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & 
                                                         within_kl == "Within"))
#add task
within.nn.v.sf.task <- glmer(Correct ~ Task + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & 
                                                         within_kl == "Within"))
#compare
anova(within.nn.v.sf.base, within.nn.v.sf.task, test= 'LRT') # significant
summary(within.nn.v.sf.task)

```


##Test 3: Do SS-knowers perform significantly better than chance on Unit Task overall?
Yes, SS-knowers performance significantly better than chance on Unit Task overall: Wald Z = 2.38, *p* = .02
```{r}
subset.sf.chance <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset" & Task == "SF"))

summary(subset.sf.chance)
```

##Test 4: Do SS-knowers perform significantly better than chance on Unit for items within their knower level? 
Yes, SS-knowers perform significantly better than chance for items within their knower level: Wald Z = 3.55, *p* = .0004
```{r}
subset.sf.chance.within <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & Task == "SF" 
                                                         & within_kl == "Within"))
summary(subset.sf.chance.within)
```

##Test 5: Is SS-knower Next Number performance significantly different than chance overall? 
Yes, but it is significantly WORSE than chance overall: Wald Z = -3.89, *p* = .0001
```{r}
subset.nn.chance <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset" & Task == "Next_number"))

summary(subset.nn.chance)
```

##Test 6: What about for numbers within SS-knowers' knower level? Is performance different than chance? 
Yes, but performance is significantly worse than chance: Wald Z = -2.25, *p* = .03
```{r}
subset.nn.chance.within <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & Task == "Next_number" & 
                                                           within_kl == "Within"))

summary(subset.nn.chance.within)
```

##Test 7: Comparison between CP and SS-knowers
###Test 7a: Unit Task 
CP-knowers are *not* performing significantly different than SS-knowers. 
```{r}
model.cp.study2 <- model.df.study2 %>%
  filter(!is.na(highest_count))

#make base
cp.subset.base <- glmer(Correct ~ age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "SF"))
summary(cp.subset.base)

#add cp_subset
cp.subset.kl <- glmer(Correct ~ CP_subset + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "SF"))
summary(cp.subset.kl)
#compare
anova(cp.subset.base, cp.subset.kl, test = 'LRT')

#add highest_count
cp.subset.hc <- glmer(Correct ~ highest_count.c + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "SF"))
#compare
anova(cp.subset.base, cp.subset.hc, test = 'LRT') #highest count is not significant
```

###Test 7b: Next Number Task 
CP-knowers are *not* performing significantly different than SS-knowers. 
```{r}
#make base
cp.subset.base.nn <- glmer(Correct ~ age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number"))


#add cp_subset
cp.subset.kl.nn <- glmer(Correct ~ CP_subset + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number"))

#compare
anova(cp.subset.base.nn, cp.subset.kl.nn, test = 'LRT') #significant

#add highest_count
cp.subset.hc.nn <- glmer(Correct ~ highest_count.c + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number")) ##NB model is failing to converge
#compare
anova(cp.subset.base.nn, cp.subset.hc.nn, test = 'LRT') #highest count is not significant
```



#Next Number - Pilot, N = 16
Do subset-knowers who succeed on Small SF do so because of an induction made over the count list? Tested children on Next Number ("*N*, what comes next?") for numbers tested on Unit Task.

##Visualization of NN and SF mean performance - subset-knowers
Make a data frame that has next number pilot data
```{r, warning=FALSE}
#warnings suppressed because factors are coerced to character
nn.data <-  read.csv("~/Documents/Projects/small_sf/Data/next_number.csv")

#filter to kids who are in the small sf dataset, only pull out the data that is necessary
nn.data %<>% 
  filter(SID %in% all.data$SID)%>%
  dplyr::select(SID, Age, Knower_level, Task_item, Response, Correct)%>%
  mutate(Task = "NN")%>%
  mutate(Correct = as.numeric(as.character(Correct)))

##do the same for small sf - pull out the kids who are in nn
sf.data <- all.data %>%
  filter(SID %in% nn.data$SID, 
         Task == "SF")%>%
  dplyr::select(SID, Age, Knower_level, Task, Task_item, Response, Correct)%>%
  mutate(Correct = as.numeric(as.character(Correct)))

##bind these two dfs together
combined.data <- bind_rows(sf.data, nn.data)

combined.data %<>%
  mutate(SID = factor(SID), 
         Task = factor(Task))
```

```{r}
combined.data %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", "Subset"))%>%
  filter(Knower_level != "CP")
```

```{r}
combined.data %>%
  mutate(Task_item = factor(Task_item))%>%
  filter(!is.na(Task_item))%>%
  filter(Knower_level != "CP")%>%
  group_by(Task, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n))%>%
  ggplot(aes(x = Task_item, y = mean, color = Task, group = Task)) + 
  geom_point(size = 2.5) + 
  geom_line(size = .7) +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = 0, size = .5) +
  theme_bw(base_size = 13) + 
  theme(legend.position = "right") + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_brewer(palette = "Dark2") + 
  labs(title = "Subset-knowers: Next Number and Unit performance")
```

##Do subset-knowers have significantly worse performance on NN than SF? 
Yes; subset-knowers have significantly better performance on SF than on NN (\beta = .9, *p* = .0001)
```{r}
subset.nn <- glmer(Correct ~ Task + Age + (1|SID),
                   family = "binomial", data = combined.data)
summary(subset.nn)

##calculating effect size - t.test approximation
#for each participant, calculate mean for each task
mean.nn <- combined.data %>%
  filter(Task == "NN")%>%
  summarise(mean.nn = mean(Correct, na.rm = TRUE))

sd.nn <- combined.data %>%
  filter(Task == "NN")%>%
  summarise(sd.nn = mean(Correct, na.rm = TRUE))

mean.sf <- combined.data %>%
  filter(Task == "SF")%>%
  summarise(mean.sf = mean(Correct, na.rm = TRUE))

sd.sf <- combined.data %>%
  filter(Task == "SF")%>%
  summarise(sd.sf = mean(Correct, na.rm = TRUE))

#calculate effect size
#(m2-m1)/sqrt((sd1^1-sd2^2)/2)
(mean.sf - mean.nn)/sqrt((sd.nn^2 + sd.sf^2)/2)

#now do a power analysis for study 2!
pwr::pwr.t.test(n = NULL, d = .5, sig.level = .05, power = .9, type = "one.sample", alternative = "two.sided")




```

##Is performance on Unit predicted by mean NN? 
```{r}
nn.ms <- combined.data %>%
  filter(Task == "NN")%>%
  group_by(SID)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

combined.data <- right_join(nn.ms, combined.data, by = "SID")

nn.from.unit <- glmer(Correct ~ mean + Task_item + (1|SID), family = "binomial", 
                      data = combined.data)
summary(nn.from.unit)

ggplot(combined.data, aes(x = mean, y = Correct, color = factor(Correct))) +
  geom_point(position = position_jitter(height = .01, width = .1))


sf.ms <- combined.data %>%
  filter(Task == "SF")%>%
  group_by(SID, mean)%>%
  summarise(mean.sf = mean(Correct, na.rm = TRUE))

cor.test(sf.ms$mean.sf, sf.ms$mean)

nn.lm <- lm(mean.sf ~ mean, data = sf.ms)
  
summary(nn.lm)

sf.ms %>%
  ggplot(aes(x = mean, y = mean.sf)) +
  geom_point() + 
  geom_smooth(method = 'lm')
```
