---
title: "Starting small: The origins of successor function knowledge in subset knowers"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    <!-- \author{{\large \bf Rose M. Schneider},^1  {\large \bf Ashlie H. Pankonin},^2 {\large \bf Adena Schachner},^1, $\&$ {\large \bf David Barner}^1 -->
    <!-- \\ ^1Department of Psychology, University of California, San Diego \\ -->
    <!-- ^2 School of Speech, Language, and Hearing Sciences, San Diego State University} -->

abstract: >
    The successor function -- a recursive function *S* which states that for every natural number *n*, *S(n)* = *n*+1 -- underlies our understanding of the natural numbers as an infinite class. Recent work has found that acquisition of this logical property is surprisingly protracted, completed several years after children master the counting procedure. While such work links successor knowledge with counting mastery, the exact processes underlying this developmental transition remain unclear. Here, we examined two possible mechanisms: (1) recursive counting knowledge, and (2) formal training with the ``+1'' rule in arithmetic. We find that while both recursive counting and arithmetic mastery predict successor knowledge, arithmetic performance is significantly lower than measures of recursive counting for all children. This dissociation suggests children do not generalize the successor function from trained mathematics; rather, we find evidence consistent with the hypothesis that successor knowledge is supported by the extraction of recursive counting rules.
    
keywords: >
    Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term.
    
output: cogsci2016::cogsci_paper
# final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, include = FALSE}
rm(list = ls())
require("knitr")
# opts_knit$set(root.dir = "~/Documents/Projects/small_sf/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)
library(memisc)
'%!in%' <- function(x,y)!('%in%'(x,y))
```

```{r}
####DATA LOADING AND MANAGEMENT
#load study 1 data
data.raw.study1 <- read.csv("../../Data/small_sf_study1.csv")
data.raw.study2 <- read.csv("../../Data/small_sf_study2.csv")

##Exclude any pilots and copypaste
data.raw.study1 %<>%
  filter(SID != "CopyPasteMe", 
         Exclusion_reason != "Pilot")%>%
  droplevels()%>%
  # dplyr::select(-X, -X.1, -X.2, -X.3, -X.4)%>%
  mutate(Age = as.numeric(as.character(Age)))

data.raw.study2 %<>%
  filter(SID != "CopyPasteMe", 
         Exclusion_reason != "Pilot")%>%
  droplevels()%>%
  # dplyr::select(-X, -X.1, -X.2, -X.3, -X.4)%>%
  mutate(Age = as.numeric(as.character(Age)))

#how many kids pre-exclusions?
#exp.1
pre.excl.exp.1 <- data.raw.study1 %>%
  distinct(SID, Age)%>%
  summarise(n = n())

#exp.2
pre.excl.exp2 <- data.raw.study2 %>%
  distinct(SID, Age)%>%
  summarise(n = n())

#Why are kids excluded?
#exp.1
excl.reason.exp1 <- data.raw.study1 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude, Exclusion_reason)%>%
  group_by(Exclusion_reason)%>%
  summarise(n = n())
#exp.2
excl.reason.exp2 <- data.raw.study2 %>%
  filter(Exclude == 1)%>%
  distinct(SID, Exclude, Exclusion_reason)%>%
  group_by(Exclusion_reason)%>%
  summarise(n = n())

#### GLOBAL EXCLUSIONS
#exp.1
data.raw.study1 %<>%
  filter(Exclude != 1)%>%
  droplevels()
#exp.2
data.raw.study2 %<>%
  filter(Exclude != 1)%>%
  droplevels()

#### TRIAL/TASK EXCLUSIONS
#exp.1
data.raw.study1 %<>%
  mutate(Exclude_trial = ifelse(is.na(Exclude_trial), "0", as.character(Exclude_trial)))%>%
  filter(Exclude_trial != "1")

#exp.2
data.raw.study2 %<>%
  mutate(Exclude_trial = ifelse(is.na(Exclude_trial), "0", as.character(Exclude_trial)))%>%
  filter(Exclude_trial != "1")


#how many kids failed training for SF?
#exp.1
fail.sf.training.exp1 <- data.raw.study1 %>%
  filter(Task == "SF", 
         Trial_number == "Training", 
         Correct == "0")%>%
  summarise(n = n())

#exp.2
fail.sf.training.exp2 <- data.raw.study2 %>%
  filter(Task == "SF", 
         Trial_number == "Training", 
         Correct == "0")%>%
  summarise(n = n())

##exclude training for SF
#exp.1
data.raw.study1 %<>%
  mutate(Trial_number = ifelse(is.na(Trial_number), "HC", as.character(Trial_number)))%>%
  filter(Trial_number != "Training")

##exclude training for SF
#exp.2
data.raw.study2 %<>%
  mutate(Trial_number = ifelse(is.na(Trial_number), "HC", as.character(Trial_number)))%>%
  filter(Trial_number != "Training")

#Exclude training for NN
data.raw.study2 %<>%
  mutate(Trial_number = ifelse(is.na(Trial_number), "HC", as.character(Trial_number)), 
         Exclude_NN = ifelse((Task == "Next_number" & Trial_number == "1"), 1, 0))%>%
  filter(Exclude_NN != 1)

## RENAME ABOVE FOR SIMPLICITY
all.data.study1 <- data.raw.study1

all.data.study2 <- data.raw.study2
```

```{r, include = FALSE}
# Data validation
## Checking knower level classifications
#study 1
given.ms <- all.data.study1 %>%
  mutate(Knower_level = ifelse(Knower_level == "CP", 6, as.numeric(as.character(Knower_level)))) %>% #for function below
  filter(Task == "Give_N", 
         !is.na(Task_item))%>%
  group_by(SID, Knower_level, Task_item)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))

#overall check - an N-knower should have gotten at least .67 mean performance for a given N
check <- given.ms %>%
  filter(Task_item == Knower_level)%>%
  filter(mean < .66)

if(length(check$SID) > 0) {
  print("CHECK STUDY 1 KLs")
}

#study 2
given.ms <- all.data.study2 %>%
  mutate(Knower_level = ifelse(Knower_level == "CP", 6, as.numeric(as.character(Knower_level)))) %>% #for function below
  filter(Task == "Give_N", 
         !is.na(Task_item))%>%
  group_by(SID, Knower_level, Task_item)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm = TRUE))

#overall check - an N-knower should have gotten at least .67 mean performance for a given N
check <- given.ms %>%
  filter(Task_item == Knower_level)%>%
  filter(mean < .66)

if(length(check$SID) > 0) {
  print("CHECK STUDY 2 KLs")
}
```

```{r}
#change correct to numeric
all.data.study1 %<>%
  mutate(Correct = as.numeric(as.character(Correct)))

all.data.study2 %<>%
  mutate(Correct = as.numeric(as.character(Correct)))
```

```{r}
##add CP_subset
#by CP_subset
#Study 1 
all.data.study1 %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", 
                            "Subset"))
#Study 2 
all.data.study2 %<>%
  mutate(CP_subset = ifelse(Knower_level == "CP", "CP", 
                            "Subset"))
```

```{r highest_count}
##add highest count as a column
#study 1
hc.lookup <- all.data.study1 %>%
  filter(Task == "Highest_count")%>%
  dplyr::rename(highest_count = Response)%>%
  dplyr::select(SID, highest_count)

all.data.study1 <- right_join(all.data.study1, hc.lookup, by = "SID")

#HCs are being read in as factors - change to numeric
all.data.study1 %<>%
  mutate(highest_count = as.numeric(as.character(highest_count)))

#one kid didn't do highest count, so we will exclude them from analyses containing hc

#study 2
hc.lookup <- all.data.study2 %>%
  filter(Task == "Highest_count")%>%
  dplyr::rename(highest_count = Response)%>%
  dplyr::select(SID, highest_count)

all.data.study2 <- right_join(all.data.study2, hc.lookup, by = "SID")

#HCs are being read in as factors - change to numeric
all.data.study2 %<>%
  mutate(highest_count = as.numeric(as.character(highest_count)))

#one kid didn't do highest count, so we will exclude them from analyses containing hc
```

# Introduction
In the course of learning about number, many children come to understand that every number is immediately succeeded by another, and that each of these +1 increases in quantity are accompanied by a +1 increased in the count list. In the US, children seem to acquire a generalized understanding of this \emph{successor function} around the age of 6 [@cheung2017; @davidson2012], with some arguing that this logical principle may fuel children's intuitions about numerical infinity [@cheung2017](CHU, citation). Acquiring knowledge of the successor function is gradual, however, and is strikingly limited for several years. For instance, many children who are otherwise competent counters have scattered knowledge of this logical principle, and are only able to reason about successor relations for a subset of the numbers within their count list [@cheung2017;@davidson2012;@sarnecka2008;@spaepen2018]. While there has been a growing body of research on the development and generalization of children's successor knowledge, there has been comparatively work exploring this early item-based successor knowledge. In the current work, we investigate the origins of children's successor knowledge, and explore the mechanisms by which children may begin to construct networks of localized successor relations, even before they fully understand the counting system. 

Similar to the successor function, the majority of children's other numerical knowledge initially begins as limited and item-based. While most US children are able to recite portions of the count list by around 2 years of age [@fuson1988], it is not until around 2.5 years that they begin to understand a meaning of a subset of those number words [@wynn1990]. Even after children become "subset knowers" [@wynn1990; @wynn1992], children acquire these meanings in isolation; e.g., a one-knower might know the meaning of \emph{one} while having no knowledge of \emph{two}. Most children learn the first several number words in isolation, until around the age of about 4 years. At this point, children suddenly seem to understand the connection between the cardinalities represented by number words and the count list which contains them -- that is, they understand how the last word said while counting indicates the cardinality of a set, i.e., the Cardinal Principle (or CP, @gelman1978). 

After acquiring the CP, children's knowledge of the successor function is far from generalized. In fact, many young CP-knowers are unable to judge whether the result of adding 1 item to sets of 4, 5, or 6 (numbers that are well within their count range) in a paradigm known as the "Unit Task" should be labeled by \emph{n}+1 or \emph{n}+2 [@sarnecka2008;@spaepen2018] (SELLA). Intriguingly, children do not reliably succeed for a large range of numbers on the Unit Task until they are extremely proficient counters [@cheung2017]; prior to demonstrating mastery of the count routine, many CP-knowers exhibit item-based successor knowledge; that is, they may be able to pass the Unit Task for some numbers in their count range while failing on others [@davidson2012]. @davidson2012 proposed that children may initially begin learning about the successor function by first establishing a network of localized successor relations, while @cheung2017 hypothesized that children may drawn upon the productive structure of the count list to extract a generalized understanding of the successor function. 

While there is growing evidence that learning the recursive nature of the count list (SCHNEIDER cites) is linked to acquiring generalized knowledge of the succcessor function, it is unclear how children may first start to establish item-based successor relations for specific, familiar numbers. Some argue that children do so by leveraging their knowledge of the ordinal structure of the count list [@spaepen2018;@sarnecka2008;@carey2009]. Because on this account children need to know both meanings of number words \emph{and} their relationship to the count list, acquiring the CP is a necessary prerequisite for success on the Unit Task; that is, the CP is a "gatekeeper" for other numerical knowledge [@spaepen2018]. 

On the other hand, children's item-based Unit Task success may not necessarily depend on having acquired the CP. The fact that children's early successor knowledge is initially specific for more familiar numbers leaves open the possibility that subset-knowers may be able to succeed on the Unit Task for numbers for which they have established meanings ("one", "two", and "three"). There is evidence that subset knowers are able to perform the basic set operations to succeed on the Unit Task, even without having access to the count lists' ordinal structure. For example, @hughes1981 found that children as young as 3 years were able to succeed on a paradigm similar to the Unit Task for small numbers (1, 2, and 3). (SELLA???) While previous work has found that subset knowers perform worse on the Unit Task in comparison to CP-knowers [@spaepen2018; @sarnecka2008], it is possible that this may be because the numbers on which they are being tested fall outside their known number range. 

In the current work, we tested these two hypotheses by exploring subset knowers’ knowledge of successor relations for very small sets (1 - 5). In Experiment 1, we asked whether subset knowers’ Unit Task performance was significantly above chance within their knower-level.In Experiment 2 we explored subset knowers’ successor knowledge in relation to their understanding of the count list in an effort to determine the mechanism through which they may be able to reason about successor relations for known number words. 

# Experiment 1
## Method
The methods and analyses for both Experiments 1 and 2 were pre-registered (https://osf.io/deqzk/?view_only=e49622708a214438bb095f18bdaa8224). All methodological and analytical choices were as pre-registered, unless stated otherwise in-text.

### Participants
```{r exp1.demos}
exp.1.demos.age <- all.data.study1 %>%
  distinct(SID, CP_subset, Age)%>%
  group_by(CP_subset)%>%
  summarise(n = n(), 
            mean_age = round(mean(Age, na.rm = TRUE), 2), 
            sd_age = round(sd(Age, na.rm = TRUE), 2))%>%
  mutate(total.n = sum(n))

exp1.demos.sex <- all.data.study1 %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))


### by n-knower level
n.levels.exp1 <- all.data.study1 %>%
  group_by(Knower_level)%>%
  distinct(SID, Age, Knower_level)%>%
  summarise(n = n(),
            mean_age = round(mean(Age, na.rm = TRUE), 2),
            sd_age = round(sd(Age, na.rm = TRUE),2))

```
We recruited `r exp.1.demos.age$total.n[1]` participants between the ages of 2 and 4 years (`r subset(exp1.demos.sex, Sex == "F")$total.n` female, $M_{age} =$ `r round(mean(all.data.study1$Age, na.rm = TRUE), 2)`, $SD_{age} =$ `r round(sd(all.data.study1$Age, na.rm = TRUE),2)`, range $=$ `r round(min(all.data.study1$Age),2)`-`r round(max(all.data.study1$Age),2)` years) from local preschools and the surrounding community in San Diego, US. `r subset(exp.1.demos.age, CP_subset == "Subset")$n` of these children were classified as subset knowers and `r subset(exp.1.demos.age, CP_subset == "CP")$n` were classified as CP-knowers using the Give-N task. The breakdown of \emph{N}-knower level classifications is shown in \ref{tab:demos1}.

\begin{table}[h]
\centering
\begin{tabular}{c c c } 
 \hline
 \emph{N}-knower level & \emph{n} & $M_{age}$ (SD) \\
 \hline
 1-knower & `r n.levels.exp1$n[1]` & `r n.levels.exp1$mean_age[1]` (`r n.levels.exp1$sd_age[1]`)\\
 2-knower & `r n.levels.exp1$n[2]` & `r n.levels.exp1$mean_age[2]` (`r n.levels.exp1$sd_age[2]`)\\ 
 3-knower & `r n.levels.exp1$n[3]` & `r n.levels.exp1$mean_age[3]` (`r n.levels.exp1$sd_age[3]`)\\
 4-knower & `r n.levels.exp1$n[4]` & `r n.levels.exp1$mean_age[4]` (`r n.levels.exp1$sd_age[4]`)\\
 CP-knower & `r n.levels.exp1$n[5]` & `r n.levels.exp1$mean_age[5]` (`r n.levels.exp1$sd_age[5]`)\\
 \hline
\end{tabular}
\caption{Demographics for all participants by knower level classification.}
\label{tab:demos1}
\end{table} 

### Procedure
Children were tested individually in a quiet spot within the classroom or museum or in room set apart from the classroom. Participants received the tasks in a fixed order (Unit Task, Give-N, and Highest Count).

#### Unit Task 
We assessed children’s successor function knowledge with a modified version of the Unit Task [@sarnecka2008]. The experimenter presented children with an opaque container and some small fish, saying, "This is my fish bowl and these are my fish!" The experimenter then placed between 1 and 5 fish in the bowl, briefly showed them to the child, and said, "Look, I have \emph{N} fish here. \emph{N} fish are swimming in the fish bowl."" If children tried to count during this presentation they were stopped by the experimenter. The experimenter then placed an opaque lid over the container and asked, "How many fish are in the fish bowl?" Children were given two opportunities to pass this memory check; if they failed both, the experimenter told them how many fish there were, and proceeded with the remainder of the trial.

After the memory check, the experimenter said, “Now watch!”, and added one fish to the container before asking, “Are there \emph{N}+1 or \emph{N}+2 fish now?”. Order of the presented alternatives was counterbalanced across trials. If children failed to pick one of the presented alternatives, the experimenter provided the alternatives again verbally and encouraged the child to select one. 

Participants completed a training trial with feedback in which only 1 fish was added to an empty bowl. Once children passed this training trial, they received 10 test trials with neutral feedback. A correct response for a given \emph{N} was \emph{N}+1. “I don’t know” responses were coded as incorrect. Only numeric responses were included in analyses; non-numeric answers were excluded. Trials were classified as either within or outside of a child’s \emph{N}-knower level (i.e., trials with 1 and 2 items were classified as “within” a 2-knower’s range). 

#### Give-N
We used a titrated version of Give-N to assess children's knower level. The experimenter provided children with 10 identical plastic objects (e.g., strawberries, bananas) and a small plastic plate. After familiarizing the child with the game, the experimenter asked them to put \emph{N} items on the plate After the child finished placing a set on the plate, the experimenter asked “Is that \emph{N}? Can you count to make sure?” If the child recognized an error, they were permitted to fix the set. 

If the child succeeded on a requested \emph{N}, the experimenter requested \emph{N}+1 on the next trial, up to six items. If the child failed on a given \emph{N}, the experimenter requested \emph{N}-1 on the next trial. This pattern of titration continued until the child’s knower level could be confidently identified. Children were defined as \emph{N}-knowers if they correctly provided \emph{N} (e.g., three strawberries) on at least two out of the three trials that \emph{N} was requested, and did not give that \emph{N} more than once when asked for another number. Children who correctly generated sets of 6 at least 2 out of 3 times when requested were classified as CP-knowers. 

#### Highest Count. 
We used the Highest Count task to assess children's counting proficiency. An experimenter introduced the task to the child by saying, “In this game, I want you to count as high as you can! Can you start counting for me with \emph{one}?" 

A child’s Highest Count was defined as the largest number counted to before making an error, or the point at which the child did not know how to continue. The first time a child stopped counting the experimenter prompted them, saying “Do you know what comes next?”. If a child could not continue, the task was ended. Otherwise, the child was able to continue counting until they stopped again. For example, a child who counted from 1 to 9, was prompted, and then continued to count to 19 had a highest count of 19. In comparison, a child who counted from 1 to 9, then skipped to 19 would have a highest count of 9.


```{r model_setup_exp1, include = FALSE}
model.df.study1 <- all.data.study1 %>%
  filter(Task == "SF", 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)))
```

```{r ss_exp_1_chance, include = FALSE}
##DO SS KNOWERS PERFORM SIGNIFICANTLY ABOVE CHANCE
#filter down to subset knowers

subset.chance.model <- glmer(Correct ~ 1 + (1|SID), family = "binomial", 
                               data = subset(model.df.study1, CP_subset == "Subset"))
subset.chance.overall <- summary(subset.chance.model)

```

```{r ss_exp_1_kl, include = FALSE}
##DO SS KNOWERS PERFORM ABOVE CHANCE WITHIN KL
##add to model.df whether a trial was within or outside knower level 
model.df.study1.within <- model.df.study1 %>%
  filter(CP_subset != "CP")%>%
  mutate(within_kl = ifelse(Task_item <= as.numeric(as.character(Knower_level)), "Within", "Outside"))

subset.chance.within.kl <- glmer(Correct ~ 1 + (1|SID), family = "binomial", 
                                 data = subset(model.df.study1.within, within_kl == "Within"))

subset.chance.within.kl.sum <- summary(subset.chance.within.kl)

```

```{r ss_exp_1_hc, include = FALSE}
##DO SS KNOWERS WITH HIGHER HC PERFORM BETTER
##get highest count for each kid, add to model.df 
subset.hc <- glmer(Correct ~ highest_count + (1|SID), 
                   family = "binomial", data = subset(model.df.study1, CP_subset == "Subset"))

#compare to base
hc.ss.anova <- anova(subset.chance.model, subset.hc, test = 'LRT')

##WHAT ABOUT WITHIN THEIR KL
subset.hc.within <- glmer(Correct ~ highest_count + (1|SID), 
                          family = "binomial", data = subset(model.df.study1.within, within_kl == "Within"))

#lrt to compare
anova(subset.chance.within.kl, subset.hc.within, test = 'LRT')
```

## Results and Discussion
Our primary question in this work was whether subset knowers were able to pass the Unit Task for numbers within their known number range, despite not yet having acquired the CP. To test this, we built a null GLMEM with subset-knower data predicting Unit Task performance, with a random effect of subject. This model indicated that subset knowers’ performance on this task was significantly different from chance (Wald \emph{Z} $=$ `r round(subset.chance.overall$coefficients[3], 2)`, $p =$ .0007), with generally accurate performance ($\beta$ $=$ `r round(subset.chance.overall$coefficients[1], 2)`). We next tested whether performance was significantly different than chance for numbers within subset knowers’ known number ranges by again building a null GLMEM, using data only from trials that were within subset knowers’ known range. Once again, we found that performance was significantly different than chance (Wald \emph{Z} $=$ `r round(subset.chance.within.kl.sum$coefficients[3], 2)`, $p$ < .0001), with higher accuracy for items which were within subset knowers' known range ($\beta$ = `r round(subset.chance.within.kl.sum$coefficients[1], 2)`). 

```{r exp_1_t_tests, include = FALSE}
subset.ms <- all.data.study1 %>%
  filter(Task == "SF", 
         CP_subset == "Subset")%>%
  group_by(SID, Knower_level, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))

##1-knowers
t.test(subset(subset.ms, Knower_level == "1" & Task_item == 1)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "1" & Task_item == 2)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "1" & Task_item == 3)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "1" & Task_item == 4)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "1" & Task_item == 5)$mean, mu = .5, var.equal = TRUE) ##NS

##2-knowers
two_knower.t.1 <- t.test(subset(subset.ms, Knower_level == "2" & Task_item == 1)$mean, mu = .5, var.equal = TRUE) ##Significant, t(17) = 6.65, p < .0001
t.test(subset(subset.ms, Knower_level == "2" & Task_item == 2)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "2" & Task_item == 3)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "2" & Task_item == 4)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "2" & Task_item == 5)$mean, mu = .5, var.equal = TRUE) ##NS

#3-knowers
three_t.test.1 <- t.test(subset(subset.ms, Knower_level == "3" & Task_item == 1)$mean, mu = .5, var.equal = TRUE) ##Significant, t(13) = 8.83, p < .0001
three_t.test.2 <- t.test(subset(subset.ms, Knower_level == "3" & Task_item == 2)$mean, mu = .5, var.equal = TRUE) ##Significant, t(13) = 3.80, p = .002
three_t.test.3 <- t.test(subset(subset.ms, Knower_level == "3" & Task_item == 3)$mean, mu = .5, var.equal = TRUE) ##Marginal, t(13) = 2.12, p = .05
t.test(subset(subset.ms, Knower_level == "3" & Task_item == 4)$mean, mu = .5, var.equal = TRUE) ##NS
t.test(subset(subset.ms, Knower_level == "3" & Task_item == 5)$mean, mu = .5, var.equal = TRUE) ##NS
```

\ref{fig:exp_1_unit} shows \emph{N}-knowers' performance on each queried item. Follow-up analyses testing N-knowers’ mean performance for individual task items against chance ($\mu$ = .5), indicated that while subset knowers’ Unit Task performance is significantly above chance levels overall, it seems that performance for small numbers increases gradually as children learn the meanings of more number words. These follow-up analyses revealed above-chance performance for 2-knowers with sets of 1 (\emph{t}(17) = `r round(two_knower.t.1$statistic, 2)`, $p$ < .0001), and for 3-knowers with sets of 1 (\emph{t}(13) = `r round(three_t.test.1$statistic, 2)`, $p$ < .0001), 2 (\emph{t}(13) = `r round(three_t.test.2$statistic, 2)`, $p$ $=$ .002), and 3 (\emph{t}(13) = `r round(three_t.test.3$statistic, 2)`, $p =$ .05). 

We also tested whether subset knowers' Unit Task performance is related to their counting knowledge by constructing another GLMEM predicting subset knowers' Unit Task performance from their highest count (centered and scaled), with a random effect of participant. A Likelihood Ratio Test between this model and a null model indicated that the addition of the highest count term did not significantly improve the fit of the model for either overall performance ($\chi^2$ $=$ `r round(hc.ss.anova$Chisq[2],2)`, $p$ $=$ 0.45, or for numbers falling within a child’s known number range ($\chi^2$ $=$ 0.65, p = 0.42). Thus, it does not appear that subset knowers’ Unit Task performance is related to their knowledge of the count list. 

```{r exp_1_unit, fig.width=3.5, fig.height=1.5, fig.align = "center", fig.cap = "Mean Unit Task performance for subset knowers in Exp. 1, grouped by knower level. Error bars represent 95\\% CIs computed by nonparametric bootstrap. Three- and 4-knowers are collapsed together due to small ns."}
#visualization 
all.data.study1 %>%
  filter(Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" )%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)), 
         Knower_level.combined = ifelse((Knower_level == "4" | Knower_level == "3"), "3- & 4-knowers", as.character(Knower_level)),
         Knower_level.combined = factor(Knower_level.combined, levels= c("1", "2", "3- & 4-knowers", "CP"), 
                               labels = c("1-knowers", "2-knowers", "3- & 4-knowers", "CP-knowers")))%>%
  filter(Task == "SF")%>%
  group_by(Task_item, Knower_level.combined)%>%
  # summarise(mean = mean(Correct, na.rm = TRUE),
  #           n = n(), 
  #           sd = sd(Correct, na.rm = TRUE), 
  #           se = sd/sqrt(n)) %>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Knower_level.combined, group= Knower_level.combined)) +
  geom_point(size = 1, 
             show.legend = FALSE) + 
  geom_line(size = .5, 
            show.legend = FALSE) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "grey", size = .5) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), 
                width = 0, size = .5, 
                show.legend = FALSE) +
  theme_bw(base_size = 7.5) + 
  theme(legend.position = "top", 
        panel.grid = element_blank()) + 
  facet_wrap(~Knower_level.combined, ncol = 3) +
  langcog::scale_color_solarized("Knower level") +
  labs(x = "Starting set size", y = "Mean Unit Task performance")
```

```{r cp_subset, include = FALSE}
###TESTING FOR DIFFERENCE BETWEEN CP AND SUBSET KNOWERS
model.cp.study1 <- all.data.study1 %>%
  filter(Task == "SF", 
         !is.na(highest_count), 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)), 
          age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)))

#construct base model with age
cp.subset.base <- glmer(Correct ~ age.c + (1|SID), 
                        family = "binomial", data = model.cp.study1)

#add knower level - does this explain additional variance?
cp.subset.kl <- glmer(Correct ~ CP_subset + age.c + (1|SID), 
                      family = "binomial", data = model.cp.study1)

#compare - does KL improve the fit of the base model? 
anova(cp.subset.base, cp.subset.kl, test = 'LRT')
cp.subset.kl.sum <- summary(cp.subset.kl)
```

```{r cp_chance, include = FALSE}
###are cp-knowers performing above chance for 4 and 5? 
cp.ms <- all.data.study1 %>%
  filter(Task == "SF", 
         CP_subset == "CP")%>%
  group_by(SID, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  ungroup()

cp.unit.t.test.4 <- t.test(subset(cp.ms, Task_item == 4)$mean, mu = .5, var.equal = TRUE)#nope
cp.unit.t.test.5 <- t.test(subset(cp.ms, Task_item == 5)$mean, mu = .5, var.equal = TRUE)#nope
```

Finally, we tested whether, consistent with previous work [@sarnecka2008; @spaepen2018], we find evidence that CP-knowers have significantly more accurate Unit Task performance than subset-knowers overall. A GLMEM predicting Unit Task performance from CP-knower status and age with a random effect of participant indicated that subset knowers were significantly less accurate in the Unit Task in comparison to CP-knowers (`r round(cp.subset.kl.sum$coefficients[2], 2)`, $p =$ .02), as shown in \ref{fig:exp_1_cp_subset}. Although CP-knowers had significantly greater Unit Task performance in comparsion to subset knowers, their performance was compatible with the hypothesis that even acquiring the CP does not guarantee implicit successor knowledge [@davidson2012; @cheung2017; @spaepen2018], as CP-knowers did not perform significantly different than chance for sets of either 4 (`r round(cp.unit.t.test.4$statistic, 2)`, $p =$  `r round(cp.unit.t.test.4$p.value, 2)`) or 5 (`r round(cp.unit.t.test.5$statistic, 2)`, $p =$  `r round(cp.unit.t.test.5$p.value, 2)`).

```{r exp_1_cp_subset, fig.width= 2.7, fig.height=1.8, fig.align = "center", fig.cap = "Mean Unit Task performance for for CP- and subset knowers in Exp. 1. Error bars represent 95\\% CIs computed by nonparametric bootstrap."}

cp.subset.pal <- c("#CAB2D6", "#6A3D9A" )
all.data.study1 %>%
    filter(Task == "SF")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP"), 
                            labels = c("Subset-knower", "CP-knower")))%>%
  group_by(Task_item, CP_subset)%>%
   # summarise(mean = mean(Correct, na.rm = TRUE), 
   #          n = n(), 
   #          sd = sd(Correct, na.rm = TRUE), 
   #          se = sd/sqrt(n)) %>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = CP_subset, group= CP_subset)) +
  geom_point(size = 1) + 
  geom_line(size = .5) +
  geom_hline(yintercept = .5, linetype = "dashed", color = "grey", size = .5) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), 
                width = 0, size = .5) +
  theme_bw(base_size = 7.5) + 
  theme(panel.grid = element_blank(), 
        legend.position = "top", 
        legend.title = element_blank(), 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(.25, 1)) + 
  scale_color_manual(values = cp.subset.pal) +
  labs(x = "Starting set size", y = "Mean Unit Task performance", 
       color = "Knower level")
```

# Experiment 2

## Method

### Participants
```{r exp2.demos}
exp.2.demos.age <- all.data.study2 %>%
  distinct(SID, CP_subset, Age)%>%
  group_by(CP_subset)%>%
  summarise(n = n(), 
            mean_age = round(mean(Age, na.rm = TRUE), 2), 
            sd_age = round(sd(Age, na.rm = TRUE), 2))%>%
  mutate(total.n = sum(n))

exp2.demos.sex <- all.data.study2 %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))


### by n-knower level
n.levels.exp2 <- all.data.study2 %>%
  group_by(Knower_level)%>%
  distinct(SID, Age, Knower_level)%>%
  summarise(n = n(),
            mean_age = round(mean(Age, na.rm = TRUE), 2),
            sd_age = round(sd(Age, na.rm = TRUE),2))

```

We recruited `r exp.2.demos.age$total.n[1]` participants between the ages of 2 and 4 years (`r subset(exp2.demos.sex, Sex == "F")$total.n` female, $M_{age} =$ `r round(mean(all.data.study2$Age, na.rm = TRUE), 2)`, $SD_{age} =$ `r round(sd(all.data.study2$Age, na.rm = TRUE),2)`, range $=$ `r round(min(all.data.study2$Age),2)`-`r round(max(all.data.study2$Age),2)` years) from local preschools and the surrounding community in San Diego, US. `r subset(exp.2.demos.age, CP_subset == "Subset")$n` of these children were classified as subset knowers and `r subset(exp.2.demos.age, CP_subset == "CP")$n` were classified as CP-knowers using the Give-N task. The breakdown of \emph{N}-knower level classifications is shown in \ref{tab:demos2}.

\begin{table}[h]
\centering
\begin{tabular}{c c c } 
 \hline
 \emph{N}-knower level & \emph{n} & $M_{age}$ (SD) \\
 \hline
 1-knower & `r n.levels.exp2$n[1]` & `r n.levels.exp2$mean_age[1]` (`r n.levels.exp2$sd_age[1]`)\\
 2-knower & `r n.levels.exp2$n[2]` & `r n.levels.exp2$mean_age[2]` (`r n.levels.exp2$sd_age[2]`)\\ 
 3-knower & `r n.levels.exp2$n[3]` & `r n.levels.exp2$mean_age[3]` (`r n.levels.exp2$sd_age[3]`)\\
 4-knower & `r n.levels.exp2$n[4]` & `r n.levels.exp2$mean_age[4]` (`r n.levels.exp2$sd_age[4]`)\\
 5-knower & `r n.levels.exp2$n[5]` & `r n.levels.exp2$mean_age[5]`\\
 CP-knower & `r n.levels.exp2$n[6]` & `r n.levels.exp2$mean_age[6]` (`r n.levels.exp2$sd_age[6]`)\\
 \hline
\end{tabular}
\caption{Demographics for all participants by knower level classification.}
\label{tab:demos2}
\end{table} 

### Procedure
Stimuli and methods were identical to Experiment 1 with two exceptions. First, we added the Next Number task to test whether subset knowers were drawing on their knowledge of the count list’s structure to succeed on the Unit Task. This task requires children to count up from an arbitrary point in the count list in response to a prompt (e.g., "\emph{N}, what comes next?"). The Next Number task included the same numbers as those tested in the Unit Task (1-5). Children received a training trial with 'one', during which they received feedback, and then received 10 additional trials. Items were present in a pseudo-randomzied order. As in Experiment 1, participants received the tasks in a fixed order (Unit Task, Next Number, Give-N, and Highest Count). 

Second, we also controlled for the possibility that children could succeed on the Unit Task through subitizing the final set when the lid was removed to add the fish during each trial. In Experiment 2, we used a lid with a small slot through which the experimenter could insert this fish, thus preventing children from observing the final set. 

## Results and Discussion

```{r exp_2_model, include= FALSE}
##This is for Next number AND SF analyses
model.df.study2 <- all.data.study2 %>%
  filter(Task == "SF" | 
           Task == "Next_number", 
         !is.na(Correct))%>%
  mutate(highest_count = as.numeric(as.character(highest_count)), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
         highest_count.c = as.vector(scale(highest_count, center = TRUE, scale = TRUE)))
```

```{r nn_vs_unit, include = FALSE}
###COMPARING NN VS UNIT FOR SS OVERALL

#make base
nn.v.sf.base <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset"))
#add task
nn.v.sf.task <- glmer(Correct ~ Task + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset"))
#compare
anova(nn.v.sf.base, nn.v.sf.task, test= 'LRT')#significant
subset.nn.unit <- summary(nn.v.sf.task)
```

```{r nn_unit_within, include = FALSE}
###TESTING WHETHER NN AND UNIT DIFFER FOR ITEMS WITHIN KL
#add a term indicating whether item is within/outside knower level
model.df.study2.within <- model.df.study2 %>%
  mutate(within_kl = ifelse(Task_item <= as.numeric(as.character(Knower_level)), "Within", "Outside"), 
         within_kl = factor(within_kl))

#make base
within.nn.v.sf.base <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & 
                                                         within_kl == "Within"))
#add task
within.nn.v.sf.task <- glmer(Correct ~ Task + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & 
                                                         within_kl == "Within"))
#compare
anova(within.nn.v.sf.base, within.nn.v.sf.task, test= 'LRT') # significant
nn.unit.subset.within <- summary(within.nn.v.sf.task)

```

```{r ss_unit_exp2, include = FALSE}
##SS UNIT CHANCE TEST
subset.sf.chance <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2, CP_subset == "Subset" & Task == "SF"))

subset.unit.exp2 <- summary(subset.sf.chance)
```

```{r ss_unit_exp2_within, include = FALSE}
##SS UNIT WITHIN CHANCE TEST
subset.sf.chance.within <- glmer(Correct ~ 1 + (1|SID), 
                      family = 'binomial', data = subset(model.df.study2.within, CP_subset == "Subset" & Task == "SF" 
                                                         & within_kl == "Within"))
subset.unit.known.exp2 <- summary(subset.sf.chance.within)
```

Our primary question in Experiment 2 was whether subset knowers' above-chance performance on the Unit Task was due to their knowledge of the count list's structure. We tested this by comparing subset knowers' performance on the Unit and Next Number tasks. First, we replicated our finding that subset knowers demonstrate above-chance Unit Task performance overall (Wald \emph{Z} $=$ `r round(subset.unit.exp2$coefficients[3], 2)`, $p =$ .012), and that this effect was driven by numbers within their known number range (Wald \emph{Z} $=$ `r round(subset.unit.exp2$coefficients[3], 2)`, $p =$ .0002). Critically, however, subset knowers' Next Number performance was significantly lower than Unit Task performance both overall ($\beta =$ -`r round(subset.nn.unit$coefficients[2,1], 2)`, $p$ < .0001), as well as for numbers within their known number range ($\beta =$ `r round(nn.unit.subset.within$coefficients[2,1], 2)`, $p$ < .0001), as shown in \ref{fig:exp_2_unit.nn}. This difference in performance between the Unit and Next Number tasks suggest that subset knowers are not drawing upon their knowledge of the count list to reason about successor relations for small numbers, but may instead be mappings between small set representations stored in working memory and known number words.

```{r exp_2_unit_nn, fig.width=3.5, fig.height=1.9, fig.align = "center", fig.cap = "Mean Unit Task and Next Number performance for subset knowers in Exp. 2, grouped by knower level. Error bars represent 95\\% CIs computed by nonparametric bootstrap. Three-, 4-, and 5- knowers are collapsed together due to small ns."}
task.pal <- c("#cb4b16", "#2aa198")

all.data.study2 %>%
   filter(Task == "SF" | 
           Task == "Next_number")%>%
  filter(Knower_level == "1" | 
           Knower_level == "2" | 
           Knower_level == "3" | 
           Knower_level == "4" | 
           Knower_level == "5")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)), 
         Knower_level.combined = ifelse((Knower_level == "4" | Knower_level == "3" | Knower_level == "5"), "3-, 4-, & 5-knowers", as.character(Knower_level)),
         Knower_level.combined = factor(Knower_level.combined, levels= c("1", "2", "3-, 4-, & 5-knowers"), 
                               labels = c("1-knowers", "2-knowers", "3-, 4-, & 5-knowers")), 
         Task = factor(Task, levels = c("Next_number", "SF"), 
                labels = c("Next Number", "Unit Task")))%>%
  group_by(Knower_level.combined, Task, Task_item)%>%
  # summarise(n = n(), 
  #           mean = mean(Correct, na.rm = TRUE), 
  #           sd = sd(Correct, na.rm = TRUE), 
  #           se = sd/sqrt(n)) %>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Task, group= Task)) +
  geom_point(size = 1) + 
  geom_line(size = .5) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), 
                width = 0, size = .5) +
  theme_bw(base_size = 7.5) + 
  theme(legend.position = "top", 
        panel.grid = element_blank(), 
        legend.title = element_blank(), 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) + 
  facet_wrap(~Knower_level.combined) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_manual(values = task.pal)+ 
  labs(x = "Number queried", y = "Mean task performance")
```

```{r, cp_nn_compare, include = FALSE}
####UNIT NN COMPARISON####
model.cp.study2 <- model.df.study2 %>%
  filter(!is.na(highest_count))
cp.nn.compare <- glmer(Correct ~ Task + (1|SID), 
                       family = "binomial", data = subset(model.cp.study2, CP_subset == "CP"))
cp.nn.sum <- summary(cp.nn.compare)

##UNIT##
cp.unit.base <- glmer(Correct ~ age.c + (1|SID), 
                       family = "binomial", data = subset(model.cp.study2, Task == "SF"))
#now add CP-subset for comparison
cp.unit.compare <- glmer(Correct ~ factor(CP_subset, levels = c("Subset", "CP")) + age.c + (1|SID), 
                       family = "binomial", data = subset(model.cp.study2, Task == "SF"))
#compare
anova(cp.unit.base, cp.unit.compare, test= 'LRT')#significant
cp.unit.2 <- summary(cp.unit.compare)

#highest count with unit
cp.unit.hc.base <- glmer(Correct ~ age.c + (1|SID), 
                       family = "binomial", data = subset(model.cp.study2, Task == "SF" & CP_subset == "CP"))
cp.unit.hc. <- glmer(Correct ~ highest_count.c + age.c + (1|SID), 
                       family = "binomial", data = subset(model.cp.study2, Task == "SF" & CP_subset == "CP"))
#compare
anova(cp.unit.hc.base, cp.unit.hc., test = 'LRT')

####Next Number####
#make base
cp.subset.base.nn <- glmer(Correct ~ age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number"))


#add cp_subset
cp.subset.kl.nn <- glmer(Correct ~ factor(CP_subset, levels = c("Subset", "CP")) + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number"))
#compare
anova(cp.subset.base.nn, cp.subset.kl.nn, test = 'LRT')
cp.nn.2 <- summary(cp.subset.kl.nn)

#add highest_count
cp.subset.hc.nn <- glmer(Correct ~ highest_count.c + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number")) ##NB model is failing to converge, need to check if this is a big deal
with(cp.subset.hc.nn@optinfo$derivs,max(abs(solve(Hessian,gradient)))<2e-3) #we're okay
#compare
anova(cp.subset.base.nn, cp.subset.hc.nn, test = 'LRT') #hc significantly adds to base model
summary(cp.subset.hc.nn)

##Add KL to HC model
nn.plus.kl <-  glmer(Correct ~ CP_subset + highest_count.c + age.c + (1|SID), 
                      family = 'binomial', data = subset(model.cp.study2, Task == "Next_number"))
#compare
anova(cp.subset.hc.nn, nn.plus.kl, test = 'LRT') #cp and NN
summary(nn.plus.kl)
```

```{r cp_chance.2, include = FALSE}
###are cp-knowers performing above chance for 4 and 5? 
cp.ms <- all.data.study2 %>%
  filter(Task == "SF", 
         CP_subset == "CP")%>%
  group_by(SID, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  ungroup()

cp.unit.t.test.4.2 <- t.test(subset(cp.ms, Task_item == 4)$mean, mu = .5, var.equal = TRUE)#nope
cp.unit.t.test.5.2 <- t.test(subset(cp.ms, Task_item == 5)$mean, mu = .5, var.equal = TRUE)#nope
```

We next tested whether there was evidence that CP-knowers drew upon their knowledge of the count list in solving the Unit Task. First, we found that CP-knowers performed significantly better than subset knowers on the Unit Task ($\beta =$ `r round(cp.unit.2$coefficients[2,1], 2)`, $p =$ .002) as well as the Next Number Task ($\beta =$ `r round(cp.nn.2$coefficients[2,1], 2)`, $p <$ .0001). As in Experiment 1, however, we again found that CP-knowers were at chance on the Unit Task for sets of 4 (`r round(cp.unit.t.test.4.2$statistic, 2)`, $p =$  `r round(cp.unit.t.test.4.2$p.value, 2)`) and 5 (`r round(cp.unit.t.test.5.2$statistic, 2)`, $p =$  `r round(cp.unit.t.test.5.2$p.value, 2)`). 

We then tested contrast our findings in subset knowers, we found no difference in CP-knowers' Unit Task and Next Number performance ($\beta =$ `r round(cp.nn.sum$coefficients[2,1], 2)`, $p =$ .21), as shown in \ref{fig:exp_2_cp_sub}. Thus, we did find some evidence that CP-knowers who have access to the ordinal structure of the count list may be able to recruit this knowledge when reasoning about successor relations for these small numbers.

```{r exp_2_cp_sub, fig.width=3.5, fig.height=1.9, fig.align = "center", fig.cap = "Mean Unit Task and Next Number performance for CP- and subset knowers in Exp. 2. Error bars represent 95\\% CIs computed by nonparametric bootstrap."}
all.data.study2 %>%
   filter(Task == "SF" | 
           Task == "Next_number")%>%
  mutate(Task_item = factor(Task_item), 
         Correct = as.numeric(as.character(Correct)), 
         Task = factor(Task, levels = c("Next_number", "SF"), 
                labels = c("Next Number", "Unit Task")), 
         CP_subset = factor(CP_subset, levels = c("Subset", "CP"), 
                            labels = c("Subset-knower", "CP-knower")))%>%
  group_by(CP_subset, Task, Task_item)%>%
  # summarise(n = n(), 
  #           mean = mean(Correct, na.rm = TRUE), 
  #           sd = sd(Correct, na.rm = TRUE), 
  #           se = sd/sqrt(n)) %>%
  langcog::multi_boot_standard("Correct", na.rm = TRUE) %>%
  ggplot(aes(x = factor(Task_item), y = mean, colour = Task, group= Task)) +
  geom_point(size = 1) + 
  geom_line(size = .5) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), 
                width = 0, size = .5) +
  theme_bw(base_size =7.5) + 
  theme(
        panel.grid = element_blank(), 
        legend.position = "top", 
        legend.title = element_blank(), 
        legend.margin=margin(1,1,1,1),
        legend.box.margin=margin(-7,-7,-7,-7)) + 
  facet_wrap(~CP_subset) + 
  scale_y_continuous(breaks = seq(0,1,.25), limits = c(0, 1)) + 
  scale_color_manual(values = task.pal)+ 
  labs(x = "Number queried", y = "Mean task performance")
```

# General Discussion
For several years before children are able to explicitly state that it is possible to add 1 to any number, they seem to have fragmented knowledge of the successor function, successfully implementing it for some familiar numbers, yet failing for others [@davidson2012]. How does this item-based knowledge arise, and what is its relationship to a fully abstracted understanding of this logical principle? We explored these questions in the current work in two ways. First, we asked whether reasoning about the successor function is possible only after CP acquisition, or whether children who have not yet learned the CP are able to implement the successor function in numbers for which they have acquired meanings. Second, we explored the possible mechanisms underlying the origins of the successor function, testing whether such knowledge relied on knowledge of the count list, or could be explained by a set-mapping mechanism. 

In two Experiments, we found that subset knowers performed significantly better than chance on the Unit Task when tested on items which could fall within their known number range. Further, we found evidence that subset knowers’ performance on the Unit Task tracked with their number word knowledge. In Experiment 2, however, we found that subset knowers were not using the count list to succeed on the Unit Task; rather, it appears that these children relied on item-based mappings between known number words and set representations stored in working memory. On the basis of these results, it is likely that children’s item-based successor knowledge may arise quite early in numerical development, and may be initially independent from count list knowledge.

Consistent with other work, however, we found that children’s successor knowledge increased after they acquired the CP, with CP-knowers out-performing subset knowers on the Unit Task in both Experiments. Further, CP-knowers’ Next Number performance was not significantly different than their Unit Task performance, suggesting that CP-knowers may already be starting to take advantage of their greater count list knowledge to reason about the successor function. Recent work has suggested that children eventually use the structure of the count list to make a full induction about the successor function (Chu et al., etc); our results indicate that even young CP-knowers may be starting to recognize the count list’s significance in solving these tasks. 

This early-emerging item-based successor knowledge may play an important role in establishing a conceptual framework which children can then leverage to generalize the successor function to all possible numbers. Our results suggest that subset knowers initially store set representations (up to 3) in working memory, and are able to perform the necessary set operations to implement the successor function over these representations, provided that they have acquired the appropriate number word meanings. When children become CP-knowers, they seem to be able to draw upon the count list to expand this localized network, although it seems like this ability is fragile, given that their Unit Task performance was lower for items beyond working memory limits. 

As children’s mastery of the count list continues to grow, the set of numbers for which they are able to reason about successor relations may increase, causing children to assert that it is possible to add +1 to some, but not all numbers. Finally, recognizing that number words are recursively generated — and that the item-based successor function that they apply to some numbers actually extends to all numbers — may support a full induction of the successor function, eventually enabling children to reason about the infinite nature of numbers [@cheung2017] (OTHER CITATIONS HERE). 

(Other summary; other future directions)



# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
